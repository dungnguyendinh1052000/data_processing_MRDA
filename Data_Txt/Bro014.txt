__z__okay .__c0
__z__eight eight .__c3
__z__we're going .__c0
__z__this is three .__c4
__z__yep .__c4
__z__three .__c3
__z__yep .__c4
__z__test .__c1
__z__huh .__c1
__fg__let's see .__c1
__qy^j^rt__move it bit .__c1
__s__test ?__c1
__s^bk__test ?__c1
__s^co__okay .__c1
__s^bk__i guess it's all right .__c1
__s^ba__so ==__c1
__s__let's see .__c1
__s^ba^fe__yeah barry's not here and dave's not here .__c1
__s^t1__um | i can say about just q- - just quickly to get through it that dave and i submitted this a. s. r. u ==__c1
__qw^t3.%--__this is for ?==__c0
__s__a. s. r. u .__c0
__s__yeah .__c1
__s__so ==__c1
__qy^rt__um ==__c1
__h__yeah it's - it's interesting .__c1
__s^j^na__i mean basically we're dealing with rever- - reverberation .__c1
__s^j__and um | when we deal with pure reverberation the technique he's using works really really well .__c1
__s^bu__uh | and when they had the reverberation here uh we'll measure the signal to noise ratio .__c1
__s^ng__and it's uh about nine d. b .__c1
__s^bk__huh .__c4
__s__so ==__c1
__s^t1__um ==__c1
__s^df__a fair amount of ==__c1
__s^t1__you mean from the actual uh recordings ?__c0
__fh__k- ==__c4
__s__yeah .__c1
__b__it's nine d. b ?__c0
__fh|s__yeah .__c1
__s^ba^fe__um ==__c1
__qy__and actually it brought up a question which may be relevant to the aurora stuff too .__c1
__fh__um i know that when you figured out the filters that we're using for the mel scale there was some experimentation that went on at - at uh - at o. g. i .__c1
__s__um ==__c1
__fh__but one of the differences that we found between the two systems that we were using the - the aurora h. t. k system baseline system and the system that we were - the - the uh other system we were using the uh the s. r. i system was that the s. r. i system had maybe a um hundred hertz high pass .__c1
__s__yep .__c4
__s^e__and the uh aurora h. t. k it was like twenty .__c1
__s^e__s- - sixty four .__c4
__fh__s- - sixty four .__c4
__s__uh ==__c1
__s^fa__sixty four ?__c1
__s__yeah .__c4
__s^bu__uh ==__c1
__fh__if you're using the baseline .__c4
__s^fa__is that the ba- - band center ?__c1
__s^bk__no .__c4
__fh__the edge .__c4
__s^cs__the edge is really uh sixty four ?__c1
__s__yeah .__c4
__fh__@@ ==__c4
__s__for some reason uh dave thought it was twenty .__c1
__s__so the uh center would be somewhere around like hundred .__c4
__s^e__but ==__c1
__s^e__and hundred and - hundred - hundred and - maybe - it's like - fi- - hundred hertz .__c4
__qw__but do you know for instance h- - how far down it would be at twenty hertz ?__c1
__s^bk__what the - how much rejection would there be at twenty hertz let's say ?__c1
__s__at twenty hertz ?__c4
__s^bk__yeah .__c1
__s^bk__any idea what the curve looks like ?__c1
__s__twenty hertz frequency .__c4
__s^aa__oh it's - it's zero at twenty hertz | right ?__c4
__s^m^na__the filter .__c4
__s^aa__yea- - actually the left edge of the first filter is at sixty four .__c3
__s^aa__sixt- - s- - sixty four .__c4
__s^t1__so ==__c3
__s__so anything less than sixty four is zero .__c4
__b__huh .__c3
__s^e__it's actually set to zero ?__c1
__s__what kind of filter is that ?__c1
__b__yeah .__c4
__fh__yeah .__c3
__s^t1__is this - oh from the - from ==__c1
__fh|s__it ==__c3
__b__this is the filter bank in the frequency domain that starts at sixty four .__c3
__fh__oh so you uh - so you really set it to zero the f. f. t .__c1
__fh|s__yeah .__c4
__s__yeah .__c4
__s__yeah .__c3
__b__so it's - it's a weight on the ball spectrum .__c4
__fh__triangular weighting .__c4
__s__right .__c1
__qw^d.%--__okay .__c1
__s^ba.x__um ==__c1
__qw^rt__okay .__c1
__s^na__so that's - that's a little different than dave thought i think .__c1
__s^df__but - but ==__c1
__b__um ==__c1
__b__still it's possible that we're getting in some more noise .__c1
__fh__so i wonder is it - @@ was there - their experimentation with uh say throwing away that filter or something ?__c1
__fh__and uh ==__c1
__s__uh throwing away the first ?__c4
__s.%--__yeah .__c1
__s__um ==__c4
__b__yeah | we - we've tried including the full - full bank .__c4
__fh__right ?__c4
__s__from zero to four k.  .__c4
__s^e__uhhuh .__c3
__s^e__and that's always worse than using sixty four hertz .__c4
__s.%--__right .__c1
__s^e__but the question is whether sixty four hertz is - is uh too uh low .__c1
__b__yeah .__c4
__b__i mean make it a hundred or so ?__c4
__s^df__yeah .__c1
__s^df__i t- - i think i've tried a hundred and it was more or less the same or slightly worse .__c4
__qy^bu^d.%--__on what test set ?__c1
__s.%-__on the same uh speechdat-car .__c4
__h|s^no__aurora .__c4
__b__um | it was on the speechdat-car .__c1
__s^na__yeah .__c4
__s^cc__so i tried a hundred to four k.  .__c4
__b__yeah .__c4
__s^df__um ==__c1
__b__so it was ==__c4
__b__and on - and on the um um t. i. digits also ?__c1
__s^df__no no no .__c4
__b__i think i just tried it on speechdat-car .__c4
__fh__huh .__c1
__b__that'd be something to look at sometime .__c1
__s__because what um uh he was looking at was performance in this room .__c1
__b__uhhuh .__c4
__s__would that be more like ?==__c1
__s__well you'd think that'd be more like speechdat-car .__c1
__b__i guess .__c1
__s^ba__in terms of the noise .__c1
__fh__the speechdat-car is more uh sort of roughly stationary a lot of it .__c1
__s^bk|s^rt__yeah .__c4
__s__and - and t. i. digits maybe is not so much as ==__c1
__s^e__uhhuh .__c3
__s^e__yeah .__c4
__s__yeah .__c1
__s__uhhuh .__c1
__s__okay .__c1
__s__well maybe it's not a big deal .__c1
__b__but um ==__c1
__b__anyway that was just something we wondered about .__c1
__fh__but um ==__c1
__s^no__uh certainly a lot of the noise uh is uh below a hundred hertz .__c1
__s^cc__uh the signal to noise ratio you know looks a fair amount better if you - if you high pass filter it from this room .__c1
__b__yeah .__c4
__s__but um ==__c1
__s__but it's still pretty noisy .__c1
__s__even - even for a hundred hertz up it's - it's still fairly noisy .__c1
__fh__uhhuh .__c3
__s__the signal to noise ratio is - is - is actually still pretty bad .__c1
__fh__huh ?__c0
__fh__so um ==__c1
__s__i mean the main - the - the ==__c1
__b__so that's on th- - that's on the f- - the far field ones though | right ?__c0
__s__yeah .__c1
__s^ba__that's on the far field .__c1
__s__yeah .__c0
__b__yeah the near field's pretty good .__c1
__fh__so wha- - what is uh - what's causing that ?__c0
__b__well we got a - a video projector in here .__c1
__s__uh ==__c1
__s^df__and | uh - which we keep on during every - every session we record .__c1
__b__yeah .__c0
__fh__which you know i - i w- - we were aware of .__c1
__fg|s^cs__but - but we thought it wasn't a bad thing .__c1
__s^bk__uhhuh .__c0
__s^aa__i mean that's a nice noise source .__c1
__s__yeah .__c0
__fh__uh | and there's also the uh - uh air conditioning .__c1
__s^aa__huh .__c0
__s^aa^r__which uh you know is a pretty low frequency kind of thing .__c1
__qy^d^rt__uhhuh .__c0
__s^bk__but - but uh ==__c1
__qrr.%--__so those are - those are major components i think .__c1
__h__i see .__c0
__s^t1__uh for the stationary kind of stuff .__c1
__fh__huh .__c0
__s.%--__um ==__c1
__s__but um ==__c1
__s^na__it uh ==__c1
__s^nd__i guess i - maybe i said this last week too .__c1
__b__but it - it - it really became apparent to us that we need to - to take account of noise .__c1
__b__and uh ==__c1
__s__so i think when - when he gets done with his prelim study i think one of the next things we'd want to do is to take this uh - uh noise uh processing stuff and - and uh - uh synthesize some speech from it .__c1
__fh__and then ==__c1
__s.%--__when are his prelims ?__c0
__s__um | i think in about um a little less than two weeks .__c1
__s^aa|s^na__oh .__c0
__fh__wow .__c0
__fh__yeah .__c1
__s^aa|s.%--__yeah .__c1
__s^fe__so ==__c1
__s^no__uh | it might even be sooner .__c1
__s__uh | let's see this is the sixteenth ?__c1
__s^bk__seventeenth ?__c1
__fh__yeah | i don't know if he's before ==__c1
__s__it might even be in a week .__c1
__s^e__so i- ==__c0
__s__a week .__c1
__s__huh .__c0
__s__week and a half .__c1
__s^no__i - i guessed that they were going to do it some time during the semester .__c0
__b__but they'll do it any time | huh ?__c0
__s^bk__they seem to be ==__c1
__s__well the semester actually is starting up .__c1
__fg__is it already ?__c0
__qo^tc__yeah .__c1
__h__the semester's late - late august they start here .__c1
__fh__yikes .__c0
__s^rt__so they do it right at the beginning of the semester .__c1
__fh__yeah .__c0
__s^no__yeah .__c1
__s__so uh ==__c1
__fh__yep .__c1
__s^bu__i mean that - that was sort of one ==__c1
__%__i mean ==__c1
__s^aa__the overall results seemed to be first place in - in - in the case of either um artificial reverberation or a modest sized training set .__c1
__s^bk__uh | either way uh i- - uh it helped a lot .__c1
__b__and - but if you had a - a really big training set a recognizer uh system that was capable of taking advantage of a really large training set ==__c1
__fg__i thought that - one thing with the h. t. k is that is has the - as we're using - the configuration we're using is w- - s- - is - being bound by the terms of aurora .__c1
__qw^rt__we have all those parameters just set as they are .__c1
__qy^rt__so even if we had a hundred times as much data we wouldn't go out to you know ten or t- - or a hundred times as many gaussians or anything .__c1
__qrr__so ==__c1
__s^no__um | it's kind of hard to take advantage of - of - of big chunks of data .__c1
__qrr.%--__uhhuh .__c3
__s^bk__huh yeah .__c4
__s.%--__uh | whereas the other one does sort of expand as you have more training data .__c1
__s^bk__it does it automatically actually .__c1
__fh__and so ==__c1
__s^bk__um ==__c1
__fg__uh ==__c1
__fh__that one really benefited from the larger set .__c1
__s__and it was also a diverse set with different noises and so forth .__c1
__fh__uh so um ==__c1
__s__that uh - that seemed to be ==__c1
__s__so if you have that - that better recognizer that can - that can build up more parameters and if you um have the natural room which in this case has a p- - a pretty bad signal to noise ratio then in that case um the right thing to do is just do - u- - use speaker adaptation and - and not bother with - with this acoustic uh processing .__c1
__b__but i think that that would not be true if we did some explicit noise processing as well as uh the convolutional kind of things we were doing .__c1
__s.%--__uhhuh .__c3
__fh__so ==__c1
__s__that's sort of what we found .__c1
__fh|s__huh .__c4
__s__i um uh started working on the uh mississippi state recognizer .__c0
__s__oh .__c4
__s__so | i got in touch with joe and - and uh from your email and things like that .__c0
__b__okay .__c4
__fh__and uh they added me to the list .__c0
__s^bk__uh the mailing list .__c0
__fh__okay .__c4
__s^bk__great .__c4
__s.%--__and he gave me all of the pointers and everything that i needed .__c0
__s__and so i downloaded the um ==__c0
__s__there were two things uh that they had to download .__c0
__b__one was the uh i guess the software .__c0
__b__and another wad - was a um sort of like a sample - a sample run .__c0
__s.%--__so i downloaded the software and compiled all of that .__c0
__fh__and it compiled fine .__c0
__qw__eight .__c4
__s^df__oh uh great .__c4
__b__no problems .__c0
__s^df__and um | i grabbed the sample stuff .__c0
__s.%--__but i haven't uh compiled it .__c0
__s__that sample was released only yesterday or the day before | right ?__c4
__s.%--__no .__c0
__x__well i haven't grabbed that one yet .__c0
__fh__so there's two .__c0
__s__oh there is another short sample set .__c4
__s.%--__there was another short one .__c0
__s^e__o- - o- - sample .__c4
__qr^d__yeah .__c0
__b__okay .__c4
__s__and so i haven't grabbed the latest one that he just uh put out yet .__c0
__b__oh okay .__c4
__s__f- - yeah okay .__c4
__b__so ==__c0
__fh__um but the software seemed to compile fine and everything .__c0
__s^cs__so ==__c0
__s__and um ==__c0
__s^nd__so ==__c0
__s^nd__is there any word yet about the issues about um adjustments for different feature sets or anything ?__c1
__s^bk__no .__c0
__s__i - i d- ==__c0
__qr__you asked me to write to him .__c0
__b__and i think i forgot to ask him about that .__c0
__b__yeah .__c1
__s__or if i did ask him he didn't reply .__c0
__s^bk__i - i don't remember yet .__c0
__s__uh | i'll - i'll d- - i'll double check that and ask him again .__c0
__fh__yeah .__c1
__fg__huh .__c4
__s__yeah .__c1
__s^df__it's like that - that could r- - turn out to be an important issue for us .__c1
__fh__huh .__c4
__fh__yeah .__c0
__qw^cs__yeah .__c1
__%--__yeah .__c0
__s^e__because they have it .__c4
__b__maybe i'll send it to the list .__c0
__s^e__yeah .__c0
__s__because they have uh already frozen those in i- - insertion penalties and all those stuff is what - i feel .__c4
__s__because they have this document explaining the recognizer .__c4
__s__uhhuh .__c0
__s__and they have these tables with uh various language model weights insertion penalties .__c4
__s.%--__u- ==__c4
__b__okay | i haven't seen that one yet .__c0
__s__uh it's th- - it's there on that web .__c4
__s.%--__so ==__c0
__b__okay .__c0
__s__and uh on that i mean they have run some experiments using various insertion penalties and all those ==__c4
__s__and so they've picked the values .__c0
__b__yeah | i think they pi- - p- ==__c4
__fh__yeah | they picked the values from ==__c4
__s__oh okay .__c0
__qw.%--__okay .__c0
__s__for r- - w- - what test set ?__c1
__b__uh | p- - the one that they have reported is a nist evaluation wall street journal .__c4
__b__but that has nothing to do with what we're testing on | right ?__c1
__b__you know .__c4
__b__uhhuh .__c3
__s.%--__no .__c4
__fh__so they're like ==__c4
__b__um ==__c4
__s.%--__so they are actually trying to uh fix that - those values using the clean uh training part of the wall street journal .__c4
__s^r__which is ==__c4
__s.%--__i mean the aurora .__c4
__s^2^rt__aurora has a clean subset .__c4
__s^aa__i mean they want to train it .__c4
__s.%--__right .__c1
__b__and then this - they're going to run some evaluations .__c4
__b__so they're set- - they're setting it based on that ?__c1
__fg__yeah .__c4
__s__okay .__c1
__s^rt__so now we may come back to the situation where we may be looking for a modification of the features to account for the fact that we can't modify these parameters .__c1
__qy^bh^rt__yeah .__c0
__s.%--__but um ==__c1
__s__yeah .__c4
__s^e__uh ==__c1
__s^e__but it's still worth i think just - since - you know just chatting with joe about the issue .__c1
__fh__yeah .__c0
__s__okay .__c0
__%--__do you think that's something i should just send to him ?__c0
__s^fe__um ==__c1
__b__or do you think i should send it to this - there's an - a m- - a mailing list ?__c0
__s^ng__well it's not a secret .__c1
__b__i mean we're you know certainly willing to talk about it with everybody .__c1
__b__but i think - i think that um um it's probably best to start talking with him just to ==__c1
__b__okay .__c0
__b__uh @@ you know it's a dialogue between two of you about what - you know what does he think about this and what - what - you know - what could be done about it .__c1
__s.%--__yeah .__c0
__s__um ==__c1
__fh__okay .__c0
__fh__if you get ten people in - involved in it there'll be a lot of perspectives based on you know how ==__c1
__s__yeah .__c0
__s__you know .__c1
__fh__right .__c0
__b__uh ==__c1
__s.%--__but i mean i think it all should come up eventually .__c1
__s__but if - if - if there is any uh uh way to move in - a way that would - that would you know be more open to different kinds of features .__c1
__s__okay .__c0
__s__but if - if uh - if there isn't and it's just kind of shut down and - and then also there's probably not worthwhile bringing it into a larger forum where - where political issues will come in .__c1
__s.%-__yeah .__c0
__s^ar__okay .__c0
__s^ar__oh .__c4
__s^ar^r__@@ so this is now - it's - it's compiled under solaris ?__c4
__s__yeah .__c0
__s__yeah okay .__c4
__b__because he - there was some mail r- - saying that it's - may not be stable for linux and all those .__c4
__s.%-__yep .__c0
__qy^rt__yeah .__c0
__fh__yeah .__c0
__s^e__i- - that was a particular version .__c0
__s.%--__susi .__c4
__h|s^cs__yeah .__c0
__s^cs^e__yeah .__c4
__b__susi or whatever it was .__c0
__b__yeah yeah .__c4
__qy^d^f^g__but we don't have that .__c0
__s__yeah okay .__c4
__s.%--__so ==__c0
__s^bsc__okay .__c4
__s.%--__that's fine .__c4
__b__should be okay .__c0
__fh__yeah it compiled fine actually .__c0
__x__yeah .__c4
__s^bu__no - no errors .__c0
__fh__nothing .__c0
__s^aa__so ==__c0
__s__that's good .__c4
__b__uh this is slightly off topic .__c1
__s__but uh ==__c1
__s__i noticed just glancing at the uh hopkins workshop uh web site that uh um one of the thing- - i don't know - well we'll see how much they accomplish but one of the things that they were trying to do in the graphical models thing was to put together a - a uh tool kit for doing uh r- - um arbitrary graphical models for uh speech recognition .__c1
__s.%--__huh .__c0
__s^2__so - and jeff uh - the two jeffs were ==__c1
__s^m^na__who's the second jeff ?__c0
__b__uh ==__c1
__fh__oh | uh do you know geoff zweig ?__c1
__s__no .__c0
__b__oh .__c1
__s.%--__uh he - he uh - he was here for a couple years .__c1
__fh__and he uh - got his p. h. d .__c1
__s__oh okay .__c0
__fg__he ==__c1
__fh__and he's uh been at i. b. m for the last couple years .__c1
__s^bu__oh okay .__c0
__fg__so ==__c1
__s^ar__wow .__c0
__s.%-__uh so he did - he did his p. h. d on dynamic bayes-nets .__c1
__s^df__that would be neat .__c0
__s.%--__uh for - for speech recognition .__c1
__s__he had some continuity built into the model .__c1
__s^co__presumably to handle some um inertia in the - in the production system .__c1
__b__and ==__c1
__s__um ==__c1
__qy^rt__huh .__c0
__qy^d^rt__so ==__c1
__qy^d^rt__huh .__c4
__s__um | i've been playing with first the um v. a. d .__c3
__s__um | so it's exactly the same approach .__c3
__b__but the features that the v. a. d neural network use are uh m. f. c. c after noise compensation .__c3
__s__oh i think i have the results .__c3
__s.%--__what was it using before ?__c1
__fh__@@ ==__c4
__b__before it was just p. l. p.'s .__c3
__s__so ==__c3
__b__yeah | it was actually ==__c4
__b__no .__c4
__qy^d^f^g__not ==__c4
__fh__i mean it was just the noisy features i guess .__c4
__s__yeah yeah yeah .__c4
__qy^d^f^g^rt__yeah .__c3
__s__noisy - noisy features .__c3
__s.%--__not compensated .__c4
__s.%-__um ==__c3
__s^j__this is what we get after this .__c3
__s.%--__so actually we yeah here the features are noise compensated .__c3
__s__and there is also the l. d. a filter .__c3
__s^r__um | and then it's a pretty small neural network which use um nine frames of - of six features from c. zero to c. fives plus the first derivatives .__c3
__s__and it has one hundred hidden units .__c3
__b__is that nine frames u- - s- - uh centered around the current frame ? or ?__c0
__qy^d^f^g__yeah .__c3
__fh__uhhuh .__c3
__fh__s- - so i'm - i'm sorry .__c1
__s^bk|s__there's - there's - there's how many - how many inputs ?__c1
__s__so it's twelve times nine .__c3
__s__twelve times nine inputs .__c1
__fh__and a hundred uh hidden .__c1
__s__hidden .__c3
__s__and ==__c3
__s.%--__two outputs .__c4
__s__two outputs .__c3
__s__two outputs .__c1
__s^e__okay .__c1
__fh|s^e__so i guess about eleven thousand parameters .__c1
__b__uhhuh .__c3
__fh|s.%--__which - actually shouldn't be a problem even in - in small phones . yeah .__c1
__qw^rt__so | i'm - i'm - s- ==__c0
__h|s.%--__it should be okay .__c3
__s^bk__so what is different between this and - and what you ?==__c0
__s__so the previous syst- ==__c3
__s__it's based on the system that has a fifty three point sixty six percent improvement .__c3
__s^e__it's the same system .__c3
__s^e__the only thing that changed is the n- - a p- - uh - a es- - the estimation of the silence probabilities .__c3
__s__uh .__c0
__s^e__okay .__c0
__fh__which now is based on uh cleaned features .__c3
__s^bk__and it's a l- - it's a lot better .__c1
__s__wow .__c0
__fh__yeah .__c3
__s^m^na__um ==__c3
__%--__that's great .__c1
__b__so it's - it's not bad .__c3
__fh|s__but the problem is still that the latency is too large .__c3
__s.%--__what's the latency ?__c1
__s__because ==__c3
__b__um ==__c3
__b__the - the latency of the v. a. d is two hundred and twenty milliseconds .__c3
__fh|s__and uh the v. a. d is used uh i- - for online normalization .__c3
__s.%--__and it's used before the delta computation .__c3
__s^bu__so if you add these components it goes t- - to a hundred and seventy .__c3
__qy^bu^d^rt__right ?__c3
__s^aa__i - i'm confused .__c1
__s__you started off with two twenty and you ended up with one seventy ?__c1
__b__with two an- - two hundred and seventy .__c3
__fh__two seventy ?__c1
__fh|s^cs__if ==__c3
__b__yeah .__c3
__s^e__if you add the c- - delta comp- - delta computation .__c3
__s^e__oh .__c1
__s^e__which is done afterwards .__c3
__b__um ==__c3
__fh__so it's two twenty .__c1
__s__i- - the- - is this - are these twenty-millisecond frames ?__c1
__b__is that why ?__c1
__fh__is it after downsampling ?__c1
__fh__the two twenty is one hundred milliseconds for the um ==__c3
__fh__or ?==__c1
__b__no | it's forty milliseconds for t- - for the uh uh cleaning of the speech .__c3
__s.%--__um ==__c3
__s.%--__then there is um the neural network which use nine frames .__c3
__s__so it adds forty milliseconds .__c3
__s^df__a- ==__c1
__fh__okay .__c1
__b__um ==__c3
__fh__after that um you have the um filtering of the silence probabilities .__c3
__b__which is a million filter .__c3
__fh__it ==__c3
__fg__and it creates a one hundred milliseconds delay .__c3
__fh__so um ==__c3
__s^bk__@@ ==__c1
__s__plus there is a delta at the input .__c4
__s__yeah .__c3
__s^e__and there is the delta at the input .__c3
__s^e__which is ==__c3
__s__one hundred milliseconds for smoothing .__c1
__s__um ==__c3
__s^bk__so it's ==__c3
__s^e__uh ==__c1
__s^bk__@@ .__c3
__s^rt__it's like forty plus - forty - plus ==__c4
__s^bk__median .__c1
__s.%--__huh .__c3
__s^bu|qy^d^g^rt__forty .__c3
__x__and then forty .__c1
__s^m^na__this forty plus twenty plus one hundred .__c3
__fh__forty p- ==__c1
__s^ba__@@ ==__c1
__fh__uh ==__c3
__s^j__so it's two hundred actually .__c4
__s^bk__yeah | there are twenty that comes from ==__c3
__qw^rt__there is ten that comes from the l. d. a filters also .__c3
__qy.%--__oh okay .__c4
__h|s__right ?__c3
__s^e__uh | so it's two hundred and ten .__c3
__fh__yeah .__c3
__fh__if you are using ==__c4
__s^no__uh ==__c1
__fh__plus the frame .__c3
__fh__t- - if you are using three frames .__c4
__fh__so it's two twenty .__c3
__b__if you are phrasing f- - using three frames it is thirty here for delta .__c4
__s__yeah | i think it's - it's five frames .__c3
__s__so five frames that's twenty .__c4
__s^df__but ==__c3
__s^df__okay .__c4
__b__so it's who un- - two hundred and ten .__c4
__fh__uh | p- - wait a minute .__c1
__b__it's forty - forty for the - for the cleaning of the speech .__c1
__s^cs^rt__so ==__c3
__%__forty cleaning .__c3
__b__forty for the i. n.  - a. n. n .__c1
__b__a hundred for the smoothing .__c1
__s.%--__yeah .__c3
__fh__well but at ten ==__c1
__fh__twenty for the delta .__c3
__fh__at th- - at the input .__c4
__s__twenty for delta .__c1
__fh__i mean that's at the input to the net .__c4
__fh__yeah .__c3
__s__delta at input to net ?__c1
__s^cs__and there i- ==__c4
__s^aa__yeah .__c3
__%--__yeah .__c4
__fh__so it's like s- - five six cepstrum plus delta .__c4
__%--__at nine - nine frames of ==__c4
__s^aa__and then ten milliseconds for ==__c1
__s^co__fi- - there's an l. d. a filter .__c4
__%-__ten milliseconds for l. d. a filter .__c1
__%-__and t- - and ten - another ten milliseconds you said for the frame ?__c1
__s__for the frame i guess .__c3
__b__i computed two twenty .__c3
__qw^rt__yeah well it's ==__c3
__fg__i guess it's for the fr - the ==__c3
__s.%--__okay .__c1
__s.%-__and then there's delta besides that ?__c1
__s^bk__so this is the features that are used by our network .__c3
__%--__and then afterwards you have to compute the delta on the uh main feature stream .__c3
__s.%--__which is um delta and double deltas .__c3
__s__okay .__c1
__s__which is fifty milliseconds .__c3
__s__yeah .__c1
__s.%--__no i mean the ==__c1
__s^bk__after the noise part the forty - the - the other hundred and eighty ==__c1
__s^bk__well | i mean ==__c1
__b__wait a minute .__c1
__s^r__some of this is uh - is uh - is in parallel | isn't it ?__c1
__qy^bu^d^rt__i mean the l. d. a ==__c1
__fh__oh you have the l. d. a as part of the v. d.  - uh v. a. d ?__c1
__s^ng__or ?==__c1
__s.%--__the v. a. d use uh l. d. a filtered features also .__c3
__s__oh it does ?__c1
__s^bk__uhhuh .__c3
__s.%--__uh .__c1
__s__so in that case there isn't too much in parallel .__c1
__qy^d^f^g__uh ==__c1
__s.%--__no .__c3
__s^e__there is um just downsampling upsampling and the l. d. a .__c3
__b__um | so the delta at the end is how much ?__c1
__fh__it's fifty .__c3
__s.%-__it's ==__c4
__s__fifty .__c1
__s__all right .__c1
__s.%-__so ==__c1
__qy^d^f^g^rt__but well we could probably put the delta um before online normalization .__c3
__s.%--__it should not that make a big difference .__c3
__s^aap__what if you used a smaller window for the delta ?__c0
__s^arp__because ==__c3
__s^e__could that help a little bit ?__c0
__s^aa__i mean i guess there's a lot of things you could do to ==__c0
__s__yeah .__c3
__s^bu__yeah .__c1
__s__yeah .__c3
__qy^d^g^rt__but nnn ==__c3
__s^m^na__so- ==__c1
__s__yeah .__c1
__s^df.%--__so if you - if you put the delta before the uh ana- - online - if ==__c1
__b__uhhuh .__c3
__s^df__yeah .__c1
__s^df__uh - then - then it could go in parallel .__c1
__b__because i- ==__c3
__s__and then y- - then you don't have that additive .__c1
__s__yep .__c4
__s^aa__yeah .__c3
__s^aa__because the time constant of the online normalization is pretty long compared to the delta window .__c3
__s__okay .__c1
__fh__so ==__c3
__s__it should not make ==__c3
__%--__okay .__c1
__b__and | you ought to be able to shove tw- - uh - sh- - uh - pull off twenty milliseconds from somewhere else to get it under two hundred .__c1
__s.%--__right ?__c1
__fh__i mean ==__c1
__s^bu^df__uhhuh .__c3
__qy^d^g^rt__is two hundred the d- ?==__c0
__fh__the hundred milla- ==__c1
__s^aa__mill- - a hundred milliseconds for smoothing is sort of an arbitrary amount .__c1
__s__it could be eighty .__c1
__s__and - and probably do @@ .__c1
__b__yeah .__c3
__fh__yeah .__c3
__b__i- - a hun- ==__c0
__fg|s^cs__uh ==__c0
__fh__wh- - what's the baseline you need to be under ?__c0
__s^cs__two hundred .__c0
__qy^d^f^g^rt__well we don't know .__c1
__s^bk__they're still arguing about it .__c1
__s.%--__@@ ==__c3
__fh__oh .__c0
__s__i mean if it's two - if - if it's uh - if it's two fifty then we could keep the delta where it is if we shaved off twenty .__c1
__s^na__if it's two hundred if we shaved off twenty we could - we could uh meet it by moving the delta back .__c1
__s^df__so how do you know that what you have is too much if they're still deciding ?__c0
__s__uh we don't .__c1
__s__but it's just ==__c1
__fh__i mean the main thing is that since that we got burned last time and - you know by not worrying about it very much we're just staying conscious of it .__c1
__fh__uhhuh .__c0
__s__oh okay .__c0
__%--__i see .__c0
__qy^d^f^g__and so th- ==__c1
__s.%--__i mean if - if - if a week before we have to be done someone says well you have to have fifty milliseconds less than you have now it would be pretty frantic around here .__c1
__s^nd__so ==__c1
__s^df^nd__uh okay .__c0
__b__uh ==__c1
__b__but still that's - that's a pretty big uh win .__c0
__s__and it doesn't seem like you're - in terms of your delay you're uh that ==__c0
__s^e__he added a bit on .__c1
__s^e__huh .__c3
__b__i guess because before we were - we were - had - were able to have the noise uh stuff uh and the l. v. a be in parallel .__c1
__s.%--__and now he's - he's requiring it to be done first .__c1
__b__well | but- - i think the main thing maybe is the cleaning of the speech which takes forty milliseconds or so .__c3
__fg__right .__c1
__fh__well so you say ==__c1
__fg__and ==__c3
__fg__let's say ten milliseconds - seconds for the l. d. a .__c1
__s^co^tc__and - but - the l. d. a is well pretty short right now .__c3
__fh__well ten .__c1
__s^bk__yeah .__c3
__s.%--__and then forty for the other .__c1
__s^rt__yeah the l. d. a - l. d. a - we don't know is like - is it very crucial for the features | right ?__c4
__s__no .__c3
__s__i just ==__c3
__s__yeah .__c4
__s__this is the first try .__c3
__s^e__i mean i - maybe the l. d. a.'s not very useful then .__c3
__s__right .__c1
__qy^rt__s- - s- - h- ==__c4
__%-__so you could start pulling back .__c1
__fh__but ==__c1
__s^no__yeah .__c4
__s^df__l- ==__c4
__b__but i think you have ==__c1
__s^rt__i mean you have twenty for delta computation .__c1
__s^e__which y- - now you're sort of doing twice .__c1
__fh__right ?__c1
__s__but yo- - w- - were you doing that before ?__c1
__fh__huh .__c3
__s^no__on the - in the ==__c4
__fh__well in the proposal um the input of the v. a. d network were just three frames i think .__c3
__s.%--__uhhuh .__c4
__s^rt__just ==__c4
__s^e__yeah | just the static no delta .__c4
__s^e__uh static features .__c3
__b__right .__c1
__s^e^rt__so what you have now is fort- - uh forty for the - the noise twenty for the delta and ten for the l. d. a .__c1
__qy^bu^rt__that's seventy milliseconds of stuff which was formerly in parallel .__c1
__%--__@@ ==__c3
__qrr.%--__right ?__c1
__s^ar__so i think ==__c1
__s^ar^r__uhhuh .__c3
__s^bk__you know that's - that's the difference as far as the timing .__c1
__s^df^rt__yeah .__c3
__s__right ?__c1
__b__um ==__c1
__s^rt__and you could experiment with cutting various pieces of these back a bit .__c1
__fh|s^rt__but ==__c1
__fh|s^rt__i mean we're s- - we're not - we're not in terrible shape .__c1
__s^df__yeah .__c0
__s__that's what it seems like to me .__c0
__s^df__uhhuh .__c3
__b__yeah .__c1
__qw__it's pretty good .__c0
__qw__it's - it's not like it's adding up to four hundred milliseconds or something .__c1
__s^e__where - where is this - where is this fifty seven point o.  two in - in comparison to the last evaluation ?__c0
__s__well it's - i think it's better than anything uh anybody got .__c1
__fh__yeah .__c3
__s^bk__oh is that right ?__c0
__fg__the best was fifty four point five .__c3
__b__yeah .__c1
__s.%--__point s- ==__c4
__s__oh .__c0
__s.%--__yeah .__c1
__s__and our system was forty nine .__c3
__fh__uh- ==__c1
__x__but with the neural network .__c3
__fh|s__wow !__c0
__s^bk__so this is almost ten percent .__c0
__s__with the f- - with the neural net .__c1
__s^df^rt__yeah .__c1
__fh|s^df^rt__yeah .__c4
__fh__and r- - and ==__c1
__fh|qw__it would- ==__c3
__s^bk|s__so this is - this is like the first proposal .__c4
__s__the proposal one .__c4
__fh__it was forty four actually .__c4
__fh|%--__yeah .__c1
__s.%--__yeah .__c1
__s^bu__and we still don't have the neural net in .__c1
__s^m^na__so - so it's ==__c1
__qy^g^t1__wow !__c0
__%--__you know .__c1
__fh__so it's ==__c1
__s^bk__we're - we're doing better .__c1
__s.%-__i mean we're getting better recognition .__c1
__s__this is - this is really good .__c0
__s^aa__i mean i'm sure other people working on this are not sitting still either .__c1
__s^df^na__but ==__c1
__b__but ==__c1
__s__yeah .__c0
__s^rt__but uh ==__c1
__s__uh ==__c1
__fh__i mean the important thing is that we learn how to do this better .__c1
__fh__and you know ==__c1
__s__so ==__c1
__fh__um ==__c1
__qy^g__yeah .__c1
__s^bk__so our ==__c1
__s__um ==__c1
__%-__yeah | you can see the kind of - kind of numbers that we're having say on speechdat-car .__c1
__s^bu.%--__which is a hard task .__c1
__fg__because it's really um - i think it's just sort of - sort of reasonable numbers starting to be .__c1
__s^co__uhhuh .__c3
__s^bu.%--__i mean it's still terri- ==__c1
__s^bk__yeah | even for a well matched case it's sixty percent error rate reduction .__c3
__s^bu.%--__which is ==__c3
__s^bu__yeah .__c1
__s^bu__yeah .__c1
__s^aa__probably half .__c1
__qy.%--__good .__c1
__s^bu.%--__um ==__c3
__fh__yeah .__c3
__qy__so actually this is in between what we had with the previous v. a. d and what sunil did with an i. d. l v. a. d .__c3
__s^aa__which gave sixty two percent improvement | right ?__c3
__s^na__yeah | it's almost that .__c4
__s^t1__so ==__c3
__fg__it's almost an average .__c4
__fg__somewhere around ==__c4
__fh__yeah .__c3
__s^bk|s^rt^tc__yeah .__c4
__s__what was that ?__c0
__s__say that last part again .__c0
__s__so if you use like an i. d. l v. a. d uh for dropping the frames ==__c3
__b__o- - o- ==__c4
__b__or the best we can get .__c4
__s__the best that we can get - i- - that means that we estimate the silence probability on the clean version of the utterances .__c3
__b__then you can go up to sixty two percent error rate reduction globally .__c3
__fh__huh .__c0
__fh|s__huh .__c3
__fh|s__yeah .__c3
__s^e__so that would be even - that wouldn't change this number down here to sixty two ?__c0
__fh__yeah .__c3
__fh__yeah .__c1
__s__so you - you were get- ==__c1
__fh__if you add a g- - good v- - very good v. a. d that works as well as a v. a. d working on clean speech .__c3
__s^bk__yeah .__c0
__qy^bu^rt__yeah .__c0
__qy.%--__then you wou- - you would go ==__c3
__s^aa__so that's sort of the best you could hope for .__c0
__fh|s^aa^r__uhhuh .__c3
__s__probably yeah .__c1
__fh|s.%--__i see .__c0
__fh__so fi- - si- - fifty three is what you were getting with the old v. a. d .__c1
__s__yeah .__c3
__x__and uh ==__c1
__s__and sixty two with the - the you know quote unquote cheating v. a. d .__c1
__qw.%-__and fifty seven is what you got with the real v. a. d .__c1
__b__uhhuh .__c3
__fh__that's great .__c1
__qw^rt__uh | yeah the next thing is i started to play ==__c3
__s.%-__well i don't want to worry too much about the delay .__c3
__s^rt__no .__c3
__s^t3__maybe it's better to wait .__c3
__s^rt__okay .__c1
__s^e^rt__for the decision .__c3
__fh__yeah .__c1
__s^co__from the committee .__c3
__qw^rt__uh | but i started to play with the um uh tandem neural network .__c3
__%-__huh ==__c3
__s^e__i just did the configuration that's very similar to what we did for the february proposal .__c3
__s^bk__and ==__c3
__s.%--__um ==__c3
__s.%-__so there is a f- - a first feature stream that use uh straight m. f. c. c features .__c3
__fg__uhhuh .__c1
__s^bk.%--__well these features actually .__c3
__s__and the other stream is the output of a neural network using as input also these um cleaned m. f. c. c .__c3
__%__um ==__c3
__s^aa__i don't have the comp- ==__c3
__s^aa__those are th- - those are th- - what is going into the tandem net ?__c0
__s^bk__huh .__c3
__fg__those two .__c0
__b__so there is just this feature stream the fifteen m. f. c. c plus delta and double delta .__c3
__s^bk__no .__c1
__s__yeah .__c0
__s__um | so it's - makes forty five features that are used as input to the h. t. k .__c3
__s.%-__and then there is - there are more inputs that comes from the tandem m. l. p .__c3
__s__oh oh .__c0
__s__okay .__c0
__s^aa__yeah .__c1
__s^aa__i see .__c0
__b__h- - he likes to use them both .__c1
__b__because then it has one part that's discriminative .__c1
__fh__uhhuh .__c0
__fh__yeah .__c3
__s__um ==__c3
__s__one part that's not .__c1
__s^bk__right .__c0
__s.%--__okay .__c0
__fg__so um ==__c3
__fg__uh yeah .__c3
__fg__right now it seems that - i- - i just tested on speechdat-car while the experiment are running on your - on t. i. digits .__c3
__s__well it improves on the well matched and the mismatched conditions .__c3
__s__but it get worse on the highly mismatched .__c3
__s^rt__um ==__c3
__qw.%--__compared to these numbers ?__c0
__%--__compared to these numbers yeah .__c3
__fh__um ==__c3
__qw__like on the well match and medium mismatch the gain is around five percent relative .__c3
__s__y- ==__c1
__s__but it goes down a lot more like fifteen percent on the h. m case .__c3
__s^aa__you're just using the full ninety features ?__c1
__s__@@ ==__c3
__fh__the ==__c3
__%--__y- - you have ninety features ?__c1
__fh__i- ==__c3
__s__i have ==__c3
__s__um ==__c3
__s^aa__from the networks it's twenty eight .__c3
__%--__so ==__c3
__s^aa^r__and from the other side it's forty five .__c1
__s__so d- - i- - it's forty five .__c3
__s^aa__so it's - you have seventy three features .__c1
__s^t1__yeah .__c3
__s^aa__and you're just feeding them like that .__c1
__fh__yeah .__c3
__s__uhhuh .__c3
__s__there isn't any k. l. t or anything ?__c1
__b__there's a k. l. t after the neural network as - as before .__c3
__s^bk|s__that's how you get down to twenty eight ?__c0
__s__yeah .__c3
__fh__why twenty eight ?__c0
__qy^rt__i don't know .__c3
__%-__uh ==__c3
__qrr__oh .__c0
__qw^rt__it's - i- - i- - i- - it's because it's what we did for the first proposal .__c3
__s__we tested uh trying to go down .__c3
__s^bk__uh .__c0
__fh__it's a multiple of seven .__c1
__fh__and ==__c3
__s^bk|s.%--__yeah .__c4
__fh__yeah .__c3
__fh|s__so ==__c3
__s^rt__um ==__c3
__s__yeah .__c4
__s^bu__i wanted to do something very similar to the proposal as a first - first try .__c3
__b__yeah .__c4
__s^aa|s^arp__i see .__c0
__qy^d^g^rt__yeah .__c1
__b__yeah .__c0
__s^ba^m__that makes sense .__c0
__qy^d^g^rt__but we have to - for sure we have to go down .__c3
__fg__because the limit is now sixty features .__c3
__s^nd__so ==__c3
__s^aa__yeah .__c1
__s^df__uh ==__c3
__qy^d^f^g^rt__we have to find a way to decrease the number of features .__c3
__b__um ==__c3
__fh__so | it seems funny that - i don't know maybe i don't u- - quite understand everything but that adding features ==__c0
__s^df__i guess - i guess if you're keeping the back end fixed .__c0
__s__maybe that's it .__c0
__fh__because it seems like just adding information shouldn't give worse results .__c0
__b__but i guess if you're keeping the number of gaussians fixed in the recognizer then ==__c0
__s__well yeah .__c1
__s__huh .__c3
__b__but i mean just in general adding information ==__c1
__s^bk__suppose the information you added well was a really terrible feature and all it brought in was noise .__c1
__s.%--__yeah .__c0
__s^df__right ?__c1
__s__so - so um ==__c1
__s^e__or - or suppose it wasn't completely terrible .__c1
__s__but it was completely equivalent to another one feature that you had .__c1
__s.%--__except it was noisier .__c1
__s__uhhuh .__c0
__qw__right ?__c1
__s__in that case you wouldn't necessarily expect it to be better at all .__c1
__s__oh yeah | i wasn't necessarily saying it should be better .__c0
__s__i'm just surprised that you're getting fifteen percent relative worse on the wel- ==__c0
__s.%--__uhhuh .__c1
__s__but it's worse .__c3
__b__on the highly mismatched condition .__c1
__b__on the highly mismatch .__c0
__s__yeah i ==__c3
__s^aa__yeah .__c0
__fh__so highly mismatched condition means that in fact your training is a bad estimate of your test .__c1
__s^aa^r__uhhuh .__c3
__s__so having - having uh a g- - a l- - a greater number of features if they aren't maybe the right features that you use certainly can e- - can easily uh make things worse .__c1
__s^aa__i mean you're right .__c1
__fg|s.%--__if you have - if you have uh lots and lots of data and you have - and your - your - your training is representative of your test then getting more sources of information should just help .__c1
__fh__but - but it's - it doesn't necessarily work that way .__c1
__s^r.%--__huh .__c0
__fh|s__uhhuh .__c3
__fh__so i wonder ==__c1
__s^bk__um ==__c1
__s__well what's your - what's your thought about what to do next with it ?__c1
__s.%--__um ==__c3
__s.%-__i don't know .__c3
__s^bk__i'm surprised .__c3
__s__because i expected the neural net to help more when there is more mismatch as it was the case for the .__c3
__fh__uhhuh .__c1
__b__so was the training set same as the p- - the february proposal ?__c4
__s__@@ ==__c4
__s^fa^t3__yeah | it's the same training set .__c3
__s__so it's timit with the t. i. digits' uh noises uh added .__c3
__s^df__okay .__c4
__s^df__uhhuh .__c1
__s^e__um ==__c3
__s^e__well we might - uh we might have to experiment with uh better training sets .__c1
__b__again .__c1
__b__uhhuh .__c3
__fh|s__but ==__c1
__s^df__i - the other thing is i mean before you found that was the best configuration but you might have to retest those things now that we have different - the rest of it is different .__c1
__s^e__right ?__c1
__b__so ==__c1
__s__um ==__c1
__b__uh ==__c1
__s__for instance what's the effect of just putting the neural net on without the o- - other - other path ?__c1
__b__uhhuh .__c3
__fh|s__i mean you know what the straight features do .__c1
__fh__yeah .__c3
__s__that gives you this .__c1
__s__uhhuh .__c3
__fh__you know what it does in combination .__c1
__s.%--__you don't necessarily know what ==__c1
__fh|s^cs^r__what if you did the ?==__c0
__fh|s^cs__would it make sense to do the k. l. t on the full set of combined features ?__c0
__b__instead of just on the ==__c0
__qy^bu^rt__yeah .__c3
__b__i g- - i guess .__c3
__qw__um ==__c3
__h|s^no__the reason i did it this ways is that in february it - we - we tested different things like that .__c3
__fh__so having two k. l. t having just a k. l. t for a network or having a global k. l. t .__c3
__fh__oh i see .__c0
__qy^rt__and ==__c3
__%--__so you tried the global k. l. t before .__c0
__s^aa__well ==__c3
__h|s^aa__yeah .__c3
__s^bk__and it didn't really ==__c0
__s^bk__and uh th- ==__c3
__s^aa^r__yeah .__c3
__s^df^rt__the differences between these configurations were not huge .__c3
__s^bk^m__i see .__c0
__s^bk__but it was marginally better with this configuration .__c3
__fh__uhhuh .__c0
__s^rt__uhhuh .__c0
__b__but yeah | that's obviously another thing to try .__c1
__s^rt__um ==__c3
__b__since things are - things are different .__c1
__fh__uhhuh .__c3
__s.%--__uhhuh .__c3
__fh__and i guess if the ==__c1
__s__these are all ==__c1
__s__so all of these seventy three features are going into um the uh - the h. m. m .__c1
__s.%--__yeah .__c3
__fh__and is - are - i- - i- - are - are any deltas being computed of tha- - of them ?__c1
__fh__of the straight features yeah .__c3
__s^ba__so ==__c3
__s.%--__n- - not of the ==__c1
__s^ba__but n- - th- - the um ==__c3
__s^bk__tandem features are u- - used as they are .__c3
__fh__are not .__c1
__fh__so ==__c3
__s__yeah | maybe we can add some context from these features also as dan did in - in his last work .__c3
__s__could .__c1
__fh|s.%--__i- ==__c1
__s__yeah .__c1
__s__but the other thing i was thinking was ==__c1
__s.%--__um ==__c1
__b__uh now i lost track of what i was thinking .__c1
__fh__but ==__c1
__fh__what is the ?==__c0
__qw.%--__you said there was a limit of sixty features or something ?__c0
__s__uhhuh .__c3
__qw__what's the relation between that limit and the um forty eight - uh forty eight hundred bits per second ?__c0
__qw.%--__oh .__c1
__h|s.%--__i know what i was going to say .__c1
__qw^t3__um | not - no relation .__c3
__h|s^rt__no relation .__c1
__b__so i - i - i don't understand .__c0
__s^rt__the f- - the forty eight hundred bits is for transmission of some features .__c3
__b__because i- ==__c0
__s__i mean if you're only using h- ==__c0
__s__and generally i- - it - s- - allows you to transmit like fifteen uh cepstrum .__c3
__s^bu__the issue was that um this is supposed to be a standard that's then going to be fed to somebody's recognizer somewhere .__c1
__%--__which might be you know it - it might be a concern how many parameters are use - u- - used and so forth .__c1
__s^bu__and so ==__c1
__s^aa__uh ==__c1
__s^aa__they felt they wanted to set a limit .__c1
__s__so they chose sixty .__c1
__s^rt__some people wanted to use hundreds of parameters .__c1
__s^aa|s^na__and - and that bothered some other people .__c1
__b__u- - and so ==__c1
__b__uhhuh .__c0
__b__they just chose that .__c1
__s^e^rt__i - i - i think it's kind of r- - arbitrary too .__c1
__s^2.%--__but - but that's - that's kind of what was chosen .__c1
__s^2__i - i remembered what i was going to say .__c1
__s^bu__what i was going to say is that um maybe - maybe with the noise removal uh these things are now more correlated .__c1
__s^aa__so you have two sets of things that are kind of uncorrelated uh within themselves .__c1
__s^aa__but they're pretty correlated with one another .__c1
__s^aa__uhhuh .__c3
__s^bu__and um ==__c1
__b__they're being fed into these uh variants only gaussians and so forth .__c1
__s__and - and uh ==__c1
__%--__uhhuh .__c3
__s^m^na__so | maybe it would be a better idea now than it was before to uh have uh one k. l. t over everything .__c1
__s^aa__uhhuh .__c3
__b__to de correlate it .__c1
__qy^bu^d__yeah i see .__c3
__b__maybe .__c1
__%__you know .__c1
__s__what are the s. n. r.'s in the training set timit ?__c4
__s^bk__it's uh ranging from zero to clean .__c3
__b__yeah .__c3
__s^2__uhhuh .__c4
__b__from zero to clean .__c3
__s^ar__yeah .__c1
__s.%--__so we found this - this uh - this macrophone data and so forth that we were using for these other experiments to be pretty good .__c1
__b__uhhuh .__c3
__s__so that's - i- - after you explore these other alternatives that might be another way to start looking is - is just improving the training set .__c1
__s^nd__uhhuh .__c3
__s^df.%--__i mean we were getting uh lots better recognition using that than ==__c1
__b__of course you do have the problem that um u- - i- - we are not able to increase the number of gaussians uh or anything to uh uh - to match anything .__c1
__fh__so we're only improving the training of our feature set .__c1
__s__but that's still probably something .__c1
__s^df.%--__so you're saying add the macrophone data to the training of the neural net ? the tandem net ?__c0
__s^df__yeah .__c1
__fh__that's the only place that we can train .__c1
__s^bk__we can't train the other stuff with anything other than the standard amount .__c1
__%--__yeah .__c0
__s__right .__c0
__s.%--__so ==__c1
__qy^bu^d^rt__um ==__c1
__s^aa__um ==__c1
__s^aa__what - what was it trained on again ?__c0
__s.%--__the one that you used .__c0
__fh|s__it's timit with noise .__c3
__fh__uhhuh .__c0
__s^bk__so yeah it's rather a small .__c3
__s__yeah .__c1
__qw^d.%--__um ==__c3
__s^ar__how big is the net by the way ?__c1
__s__uh | it's uh five hundred hidden units .__c3
__s^t3.%--__and ==__c3
__fh__and again you did experiments back then where you made it bigger .__c1
__b__and it - and that was - that was sort of the threshold point .__c1
__s^bk__much less than that it was worse .__c1
__s^e.%--__yeah .__c3
__qr__and ==__c1
__s__yeah .__c3
__s__much more than that it wasn't much better .__c1
__fh__huh .__c1
__s^bk__so is it - is it though the performance big relation in the high ma- - high mismatch has something to do with the uh cleaning up that you - that is done on the timit after adding noise ?__c4
__s__yeah .__c3
__b__@@ ?__c3
__b__so ==__c4
__qy^bu^d^rt__it's - i- - all the noises are from the t. i. digits .__c4
__h__right ?__c4
__s^aa__yeah .__c3
__fg__so you - i- ==__c4
__fg__um ==__c3
__s.%-__well it- - it's like the high mismatch of the speechdat-car .__c4
__qw__they - k- - uh ==__c3
__s^df__after cleaning up maybe having more noise than the - the training set of timit after clean - s- - after you do the noise cleanup .__c4
__fg__huh .__c3
__s^bk__i mean earlier you never had any compensation .__c4
__s^aa^t3__you just trained it straight away .__c4
__s^na^t3__uhhuh .__c3
__s__so it had like all these different conditions of s. n. r.'s actually in their training set of neural net .__c4
__s^aa^t3__uhhuh .__c3
__s^e__uhhuh .__c3
__s^e__but after cleaning up you have now a different set of s. n. r.'s | right ?__c4
__s^bk__yeah .__c3
__s__for the training of the neural net .__c4
__s^bk__uhhuh .__c3
__s^bk__and ==__c4
__s.%--__is it something to do with the mismatch that - that's created after the cleaning up like the high mismatch ?__c4
__s__you mean the - the most noisy occurrences on speechdat-car might be a lot more noisy than ?==__c3
__s^rt__uhhuh .__c4
__b__of - that ==__c4
__b__i mean the s. n. r after the noise compensation of the speechdat-car .__c4
__s__oh .__c1
__x__so right .__c1
__s^bk__so the training - the - the neural net is being trained with noise compensated stuff .__c1
__s^e^rt__maybe .__c3
__b__@@ ==__c4
__s^bk__yeah .__c4
__s^bk__yeah .__c3
__s.%--__yeah .__c3
__b__yeah .__c4
__s^bk__which makes sense .__c1
__qy.%--__but uh | you're saying - yeah the noisier ones are still going to be - even after our noise compensation are still going to be pretty noisy .__c1
__qy__yeah .__c4
__%--__uhhuh .__c3
__qy^d^e^rt__yeah | so now the after noise compensation the neural net is seeing a different set of s. n. r.'s than that was originally there in the training set of timit .__c4
__s^aa__because in the timit it was zero to some clean .__c4
__qw__right .__c1
__s^aa__yes .__c1
__qy^rt__so the net saw all the s. n. r @@ conditions .__c4
__s.%--__right .__c1
__s^nd__now after cleaning up it's a different set of s. n. r .__c4
__s^e^nd__right .__c1
__s^bk__and that s. n. r may not be like com- - covering the whole set of s. n. r.'s that you're getting in the speechdat-car .__c4
__b__right .__c1
__s^fa__but the speechdat-car data that you're seeing is also reduced in noise .__c1
__fg|s.%--__yeah yeah yeah .__c4
__fg__yeah .__c3
__b__by the noise compensation .__c1
__b__yeah it is .__c4
__fh__but i'm saying there could be some - some issues of .__c4
__s.%-__so ==__c1
__s__uhhuh .__c3
__s^ar__yeah .__c1
__fh__well if the initial range of s. n. r is different we - the problem was already there before .__c3
__s^nd^rt__and ==__c3
__s^bk__yeah .__c1
__s.%-__because ==__c3
__s__huh ==__c3
__b__yeah | i mean it depends on whether you believe that the noise compensation is equally reducing the noise on the test set and the training set .__c1
__b__huh .__c3
__s__on the test set yeah .__c4
__s__uh ==__c1
__s^bk__@@ ==__c4
__b__right ?__c1
__s^bk__i mean you're saying there's a mismatch in noise that wasn't there before .__c1
__s__huh .__c4
__b__uhhuh .__c4
__s^t3.%--__uhhuh .__c4
__%--__but if they were both the same before then if they were both reduic- - reduced equally then there would not be a mismatch .__c1
__b__so ==__c1
__fh__i mean this may be ==__c1
__b__heaven forbid this noise compensation process may be imperfect .__c1
__s^ar__but ==__c1
__s^aa__uh ==__c1
__s.%--__yeah uh ==__c3
__s^df__well i ==__c4
__fg__so maybe it's treating some things differently .__c1
__qy.%--__i don't know .__c4
__s.%--__i - i just - that could be seen from the t. i. digits uh testing condition .__c4
__s.%-__because um the noises are from the t. i. digits | right ?__c4
__s^2__noise .__c4
__s^aa__yeah .__c3
__s^m^na__so ==__c3
__s^na__so cleaning up the t. i. digits .__c4
__s^bk__and if the performance goes down in the t. i. digits mismatch - high mismatch like this ==__c4
__s^bk__clean training yeah .__c3
__b__on a clean training or zero d. b testing .__c4
__b__yeah we'll - so we'll see .__c3
__s__yeah .__c4
__b__uh ==__c3
__s^bk__then it's something to do .__c4
__fg|%--__maybe .__c3
__s^bk__uhhuh .__c3
__s.%--__yeah .__c3
__s^co__i mean one of the things about ==__c1
__b__i mean the macrophone data um i think you know it was recorded over many different telephones .__c1
__fh|s__uhhuh .__c3
__b__and um ==__c1
__b__so | there's lots of different kinds of acoustic conditions .__c1
__s^e__i mean it's not artificially added noise or anything .__c1
__s^t3__so it's not the same .__c1
__qy^t3.%--__i don't think there's anybody recording over a car - from a car .__c1
__qy^r^t3__but - i think it's - it's varied enough that if - if doing this adjustments uh and playing around with it doesn't uh make it better the most - uh it seems like the most obvious thing to do is to improve the training set .__c1
__s__um ==__c1
__s^2^t3.%--__i mean what we were ==__c1
__s^aa^t3__uh - the condition - it - it gave us an enormous amount of improvement in what we were doing with meeting recorder digits .__c1
__s^na^t3__even though there again these m- - macrophone digits were very very different from uh what we were going on here .__c1
__s^nd^t3__i mean we weren't talking over a telephone here .__c1
__b__but it was just - i think just having a - a nice variation in acoustic conditions was just a good thing .__c1
__qy^d^f^g^rt__uhhuh .__c3
__b__yep .__c3
__s__huh .__c4
__s^aa^t3__yeah actually to s- - uh what i observed in the h. m case is that the number of deletion dramatically increases .__c3
__s__it - it doubles .__c3
__s^na^t3__number of deletions .__c1
__s^t3__when i added the num- - the neural network it doubles the number of deletions .__c3
__s^ar^t3__yeah so i don't you know how to interpret that .__c3
__s^rt^t3__but huh ==__c3
__s^rt^t3__yeah .__c1
__s^t3__me either .__c1
__b__t- ==__c3
__b__and - and did - an- - other numbers stay the same ?__c0
__s^bk^t3__insertion substitutions stay the same ?__c0
__s^t3.%--__they p- - stayed the same .__c3
__s^t3__they - maybe they are a little bit uh lower .__c3
__b__roughly .__c0
__s__uhhuh .__c0
__s^t3__they are a little bit better .__c3
__s^m^na^t3__yeah but ==__c3
__s^aa^t3__uhhuh .__c3
__b__did they increase the number of deletions even for the cases that got better ?__c1
__s__say for the - i mean it ==__c1
__s^bk__no it doesn't .__c3
__b__no .__c3
__s__so it's only the highly mismatched .__c1
__s^e__and it - remind me again .__c1
__b__the highly mismatched means that the ==__c1
__b__clean training and ==__c3
__s__uh sorry ?__c1
__s__it's clean training ==__c3
__s^df__well close microphone training and distant microphone um high speed i think .__c3
__s^df__close mike training .__c1
__s^aa__well .__c3
__s^df__the most noisy cases are the distant microphone for testing .__c3
__s^aa__right .__c1
__s^df__so ==__c1
__s.%--__well maybe the noise subtraction is subtracting off speech .__c1
__fh__separating .__c3
__s__yeah .__c3
__s__but ==__c3
__s.%--__wh- ==__c1
__s^bk__yeah .__c3
__s__i mean but without the neural network it's - well it's better .__c3
__s.%--__it's just when we add the neural networks .__c3
__s^bk__the feature are the same except that ==__c3
__b__yeah right .__c1
__s__uh that's right that's right .__c1
__s^df^r__um ==__c1
__b__well that - that says that you know the um - the models in - in uh the recognizer are really paying attention to the neural net features .__c0
__fh__yeah .__c3
__s__uhhuh .__c3
__s__uh ==__c0
__s^aa__but yeah .__c1
__fh|s^cs__actually the timit noises are sort of a range of noises .__c1
__s^df__and they're not so much the stationary driving kind of noises | right ?__c1
__b__it's - it's pretty different .__c1
__s__isn't it ?__c1
__b__uh | there is a car noise .__c3
__qw__so there are f- - just four noises .__c3
__s.%--__um ==__c3
__s__uh car i think .__c3
__s__babble .__c4
__b__babble .__c3
__b__subway | right ?__c3
__s__and ==__c3
__qh^bh^rt__street or airport or something .__c4
__fh__and - street isn't ==__c3
__s__or train station .__c4
__fh__train station yeah .__c3
__s^ba__yeah .__c4
__fg__so - it's mostly - well car is stationary .__c3
__qy^bu^d^rt__uhhuh .__c1
__s^nd__babble it's a stationary background plus some voices .__c3
__s^bk__uhhuh .__c1
__s^nd.%--__some speech over it .__c3
__b__and the other two are rather stationary also .__c3
__b__well | i - i think that if you run it ==__c1
__s^nd__actually you - maybe you remember this .__c1
__s.%--__when you - in - in the old experiments when you ran with the neural net only and didn't have this side path um uh with the - the pure features as well did it make things better to have the neural net ?__c1
__fg__uhhuh .__c3
__s^bk__was it about the same ?__c1
__s.x__uh w- - i- ==__c1
__s__it was b- - a little bit worse .__c3
__b__than ?==__c1
__b__than just the features .__c3
__s^nd__yeah .__c3
__fh__so ==__c1
__b__until you put the second path in with the pure features the neural net wasn't helping at all .__c1
__b__uhhuh .__c3
__b__well that's interesting .__c1
__s^nd__it was helping uh if the features are b- - were bad .__c3
__qy^bu^d.%--__i mean ==__c3
__qy^rt__yeah .__c1
__s^na__just plain p. l. p.'s or m. f. c. c.'s .__c3
__s^aa__yeah .__c1
__b__but ==__c3
__b__as soon as we added l. d. a online normalization and all these things then ==__c3
__fh__they were doing similar enough things .__c1
__s__well i still think it would be k- - sort of interesting to see what would happen if you just had the neural net without the side thing .__c1
__s__yeah .__c3
__s^df.%--__uhhuh .__c3
__s^ar__and - and the thing i - i have in mind is uh maybe you'll see that the results are not just a little bit worse .__c1
__s^df.%--__maybe that they're a lot worse .__c1
__s^bk^fe__you know ?__c1
__s.%--__and um ==__c1
__b__but if on the ha- - other hand uh it's say somewhere in between what you're seeing now and - and - and uh what you'd have with just the pure features then maybe there is some problem of a - of a uh combination of these things or correlation between them somehow .__c1
__qy^2__uhhuh .__c3
__s^aa__if it really is that the net is hurting you at the moment then i think the issue is to focus on - on uh improving the - the net .__c1
__s^na^r.%--__yeah .__c3
__qy^d^rt__uhhuh .__c3
__s^aa__um ==__c1
__s^bk__so what's the overall effe- ?==__c1
__s^rt__i mean you haven't done all the experiments .__c1
__s^ba^bk__but you said it was i- - somewhat better say five percent better for the first two conditions and fifteen percent worse for the other one ?__c1
__s^bk__but it's - but of course that one's weighted lower .__c1
__s.%--__y- - yeah oh .__c3
__s^bk__yeah .__c3
__s__so i wonder what the net effect is .__c1
__s^df^rt__i d- - i - i think it's - it was one or two percent .__c3
__s^bk__that's not that bad .__c3
__%--__but it was l- - like two percent relative worse on speechdat-car .__c3
__s__i have to - to check that .__c3
__s^bk__well i have - i will .__c3
__s^bk__well it will - overall it will be still better .__c4
__fg__even if it is fifteen percent worse .__c4
__s__because the fifteen percent worse is given like f- - w- - twenty five point two five eight .__c4
__s^df__right .__c1
__b__uhhuh .__c3
__s^df__huh .__c3
__s^bu.%--__right .__c1
__s__so the - so the worst it could be if the others were exactly the same is four .__c1
__s^m^na.%--__is it like ==__c4
__s^aa__yeah so it's four .__c4
__s__and - and uh | in fact since the others are somewhat better ==__c1
__fh__is i- ==__c4
__s^bu__so either it'll get cancelled out or you'll get like almost the same .__c4
__s^aa__yeah it was - it was slightly worse .__c3
__qy^d^g^rt__uh ==__c1
__s^bk__slightly bad .__c4
__b__yeah .__c4
__fg__um ==__c3
__b__yeah it should be pretty close to cancelled out .__c1
__qy^rt__yeah .__c4
__s^ar__uhhuh .__c3
__s^nd__you know i've been wondering about something .__c0
__qy^d^e^rt__in the um - a lot of the um - the hub five systems um recently have been using l. d. a .__c0
__s^nd^r__and - and they um they run l. d. a on the features right before they train the models .__c0
__s__so there's the - the l. d. a is - is right there before the h. m. m.'s .__c0
__s^bk__yeah .__c4
__s__so you guys are using l. d. a .__c0
__s__but it seems like it's pretty far back in the process .__c0
__s^na__uh this l. d. a is different from the l. d. a that you are talking about .__c4
__fg__the l. d. a that you saying is like you take a block of features like nine frames or something and then do an l. d. a on it .__c4
__s__yeah .__c0
__b__uhhuh .__c0
__s__and then reduce the dimensionality to something like twenty four or something like that .__c4
__b__yeah | you c- - you c- - you can .__c0
__b__and then feed it to h. m. m .__c4
__b__i mean it's - you know you're just basically i- ==__c0
__%--__yeah | so this is like a two d- - two dimensional tile .__c4
__s.%--__you're shifting the feature space .__c0
__s^ar__yeah .__c0
__fg__so this is a two dimensional tile .__c4
__s^cs__and the l. d. a that we are f- - applying is only in time .__c4
__fh__not in frequency .__c4
__s^bk__high cost frequency .__c4
__b__so it's like - more like a filtering in time .__c4
__s^bk__rather than doing a r- ==__c4
__s^ba__uh okay .__c0
__b__so what i- - what about um - i- - u- - what i- - w- ?==__c0
__s^am__i mean i don't know if this is a good idea or not .__c0
__s^bd__but what if you put - ran the other kind of l. d. a uh on your features right before they go into the h. m. m ?__c0
__s^df__uh it ==__c4
__b__uhhuh .__c3
__fh__no actually i think - i- ==__c3
__qy^rt__m- ==__c4
__h|s^am__well .__c3
__s^ar__what do we do with the a. n. n is - is something like that .__c3
__s^am__except that it's not linear .__c3
__fh__but it's - it's like a nonlinear discriminant analysis .__c3
__b__yeah .__c0
__s.%--__right .__c0
__qw__it's the - it's ==__c0
__qy^e^rt__right .__c0
__qrr^e^rt__the - so ==__c0
__fh__but ==__c3
__s__yeah so it's sort of like ==__c0
__qw__the tandem stuff is kind of like i- - nonlinear l. d. a .__c0
__s^bk^m__yeah .__c3
__s^bk__it's ==__c3
__fh__i g- ==__c0
__s__yeah .__c3
__s^2__yeah .__c1
__qy^d^g^rt__yeah .__c0
__s^aa__uh ==__c3
__s__but i mean w- - but the other features that you have um th- - the non tandem ones ==__c0
__fh__uhhuh .__c3
__fh__yeah i know .__c3
__s.%--__that - that - yeah .__c3
__s__well in the proposal they were transformed u- - using p. c. a .__c3
__s^aa__but ==__c3
__s^cs__uhhuh .__c0
__s^am__yeah it might be that l. d. a could be better .__c3
__s^na__the a- - the argument i- - is kind of i- - in ==__c1
__s^df.%--__and it's not like we really know .__c1
__s^e__but the argument anyway is that um uh we always have the prob- ==__c1
__b__i mean discriminative things are good .__c1
__b__l. d. a neural nets they're good .__c1
__b__yeah .__c0
__b__uh they're good because you - you - you learn to distinguish between these categories that you want to be good at distinguishing between .__c1
__fg__and p. c. a doesn't do that .__c1
__b__it - p. a. c.- - p. c. a low order p. c. a throws away pieces that are uh maybe not - not going to be helpful just because they're small basically .__c1
__qo^tc__right .__c0
__h__but uh | the problem is training sets aren't perfect and testing sets are different .__c1
__s__so you f- - you - you face the potential problem with discriminative stuff be it l. d. a or neural nets that you are training to discriminate between categories in one space .__c1
__s^cc__but what you're really going to be g- - getting is - is something else .__c1
__fh__uhhuh .__c0
__fh__and so uh stephane's idea was uh let's feed uh both this discriminatively trained thing and something that's not .__c1
__s^bk__so you have a good set of features that everybody's worked really hard to make .__c1
__qy__yeah .__c0
__h__and then uh you - you discriminately train it .__c1
__qrr.%--__but you also take the path that - that doesn't have that .__c1
__s^nd__uhhuh .__c0
__s^cc__and putting those in together .__c1
__fh__and that - that seem- ==__c1
__b__so it's kind of like a combination of the uh what uh dan has been calling you know a feature - uh you know a feature combination versus posterior combination or something .__c1
__s__it's - it's you know you have the posterior combination .__c1
__s^df.%--__but then you get the features from that and use them as a feature combination with these - these other things .__c1
__s__and that seemed at least in the last one as he was just saying he - he - when he only did discriminative stuff i- - it actually was - was - it didn't help at all in this particular case .__c1
__qw__yeah .__c0
__fh__there was enough of a difference i guess between the testing and training .__c1
__s__but by having them both there ==__c1
__s^bk^m__the fact is some of the time the discriminative stuff is going to help you .__c1
__b__uhhuh .__c0
__qy^d^rt__and some of the time it's going to hurt you .__c1
__qy^d^rt__and by combining two information sources if you know - if - if ==__c1
__qy^d^rt__right .__c0
__s^no__so you wouldn't necessarily then want to do l. d. a on the non tandem features because now you're doing something to them that ==__c0
__%--__that i- - i- ==__c1
__b__i think that's counter to that idea .__c1
__b__yeah .__c0
__b__now again it's - we're just trying these different things .__c1
__fg__right .__c0
__s^tc__we don't really know what's going to work best .__c1
__s.%--__but if that's the hypothesis at least it would be counter to that hypothesis to do that .__c1
__s^aa__right .__c0
__s__um ==__c1
__s^df__and in principle you would think that the neural net would do better at the discriminant part than l. d. a .__c1
__fh__right .__c0
__s^co__yeah .__c0
__fh|qy^rt__though maybe not .__c1
__fh__well - y- ==__c0
__s^na^rt__yeah .__c0
__s^aa__exactly .__c0
__s^aa__i mean we uh - we were getting ready to do the tandem uh stuff for the hub five system .__c0
__s^no__and um | andreas and i talked about it .__c0
__s^fa__and the idea w- - the thought was well uh yeah that i- - you know - th- - the neural net should be better .__c0
__%--__but we should at least have uh a number you know to show that we did try the l. d. a in place of the neural net .__c0
__s^cs^j__so that we can you know show a clear path .__c0
__s^bk__right .__c1
__s^df.%-__you know that you have it without it .__c0
__s__then you have the l. d. a .__c0
__s__then you have the neural net .__c0
__s^cs^j__and you can see theoretically .__c0
__%__so ==__c0
__%__i was just wondering ==__c0
__s^ar__i - i ==__c0
__s.%--__well i think that's a good idea .__c1
__s^j__yeah .__c0
__s^j__did - did you do that ?__c1
__%--__or - tha- - that's a ?==__c1
__b__um no .__c0
__s^j__that's what - that's what we're going to do next .__c0
__s.%--__as soon as i finish this other thing .__c0
__fg__yeah .__c1
__qy^d.%--__so ==__c0
__h|s^nd__yeah .__c1
__qy^d__no well that's a good idea .__c1
__s__i - i ==__c1
__s__i- - yeah .__c1
__fh__we just want to show .__c0
__fh|s__i mean it - everybody believes it .__c0
__s^df__oh no .__c1
__b__it's a g- ==__c1
__s^df__but you know we just ==__c0
__s^cc__no no .__c1
__s^cc__but it might not - not even be true .__c1
__s^cc__i mean it's - it's - it's - it's - it's a great idea .__c1
__s^bu__yeah .__c0
__h__i mean one of the things that always disturbed me uh in the - the resurgence of neural nets that happened in the eighties was that um a lot of people - because neural nets were pretty easy to - to use a lot of people were just using them for all sorts of things without uh looking at all into the linear uh - uh versions of them .__c1
__qy^d^g__yeah .__c0
__%--__uhhuh .__c0
__s^arp__and uh | people were doing recurrent nets but not looking at i. i. r filters .__c1
__qy^bh^rt__yeah .__c0
__s^df__and - you know i mean uh ==__c1
__s^df__so i think yeah it's definitely a good idea to try it .__c1
__s^bk__yeah .__c0
__s^bk__and everybody's putting that on their systems now .__c0
__s.%--__and so i- ==__c0
__fh__that's what made me wonder about this .__c0
__s__well they've been putting them in their systems off and on for ten years .__c1
__b__but ==__c0
__fh__but - but - but uh ==__c1
__s^cs__yeah | what i mean is it's - it's like in the hub five evaluations you know .__c0
__s^aa|s^na__and you read the system descriptions and everybody's got you know l. d. a on their features .__c0
__fh__and now they all have that .__c1
__fh|s__i see .__c1
__fg__and so .__c0
__s^2__yeah .__c1
__fh__uh ==__c0
__b__it's the transformation they're estimating on .__c3
__s^bk__well they are trained on the same data as the final h. m. m are .__c3
__s^no__yeah | so it's different .__c0
__qw__yeah .__c0
__h|s__exactly .__c0
__s.%--__because they don't have these you know mismatches that - that you guys have .__c0
__fh__uhhuh .__c3
__s^no__so that's why i was wondering if maybe it's not even a good idea .__c0
__s^na__uhhuh .__c3
__s^cc__i don't know .__c0
__s^cs__i - i don't know enough about it .__c0
__s^bk__uhhuh .__c3
__b__but - um ==__c0
__s.%--__i mean part of why ==__c1
__s__i - i think part of why you were getting into the k. l. t - y- - you were describing to me at one point that you wanted to see if uh you know getting good orthogonal features was - and combining the - the different temporal ranges - was the key thing that was happening or whether it was this discriminant thing | right ?__c1
__s^bk__so you were just trying ==__c1
__s^bk__i think you r- ==__c1
__b__i mean this is - it doesn't have the l. d. a aspect .__c1
__b__but th- - as far as the orthogonalizing transformation you were trying that at one point | right ?__c1
__qo__uhhuh .__c3
__h__uhhuh .__c3
__s__i think you were .__c1
__s__yeah .__c3
__fh__does something .__c1
__s^e__it doesn't work as well .__c1
__fh__yeah .__c1
__s__yeah .__c1
__s__so yeah .__c4
__s^rt__i've been exploring a parallel v. a. d without neural network .__c4
__b__with like less latency using s. n. r and energy um after the cleaning up .__c4
__s.%--__so what i'd been trying was um ==__c4
__s__uh ==__c4
__s^rt__after the b- - after the noise compensation n- - i was trying t- - to f- - find a f- - feature based on the ratio of the energies that is cl- - after clean and before clean .__c4
__b__so that if - if they are like pretty c- - close to one which means it's speech .__c4
__fh__and if it is n- - if it is close to zero which is - so it's like a scale @@ probability value .__c4
__s^bk__so i was trying uh with full band and multiple bands .__c4
__s__m- - ps- - uh - separating them to different frequency bands .__c4
__s^aa__and deriving separate decisions on each bands and trying to combine them .__c4
__s__uh ==__c4
__s^aa__the advantage being like it doesn't have the latency of the neural net if it - if it can .__c4
__s^bu__uhhuh .__c1
__s^bk__g- - and it gave me like uh one point - one - more than one percent relative improvement .__c4
__s.%--__so from fifty three point six it went to fifty f- - four point eight .__c4
__fh__so it's like only slightly more than a percent improvement .__c4
__s^ng__uhhuh .__c1
__b__just like ==__c4
__b__which means that it's - it's doing a slightly better job than the previous v. a. d .__c4
__s.%--__uhhuh .__c1
__fg|s^cs__uh | at a l- - lower delay .__c4
__s__uhhuh .__c1
__s^bk__um ==__c4
__s^bk__so um ==__c4
__s__so - u- ==__c4
__s^bk__but ==__c1
__qy^d^f^g^rt__i- - d- - i'm sorry .__c1
__b__does it still have the median filter stuff ?__c1
__s.%--__it still has the median filter .__c4
__fh__so it still has most of the delay .__c1
__%__so ==__c4
__b__it just doesn't ==__c1
__b__yeah .__c4
__s__so d- - with the delay that's gone is the input which is the sixty millisecond .__c4
__s^bk__the forty plus twenty .__c4
__s^m^na__at the input of the neural net you have this uh f- - nine frames of context plus the delta .__c4
__fh__well w- - i- ==__c1
__b__uhhuh .__c3
__b__oh plus the delta .__c1
__b__right .__c1
__s.%-__yeah .__c4
__qy^cs^rt__okay .__c1
__s^co^na__so that delay plus the l. d. a .__c4
__s^co__uhhuh .__c1
__s^bk__uh so the delay is only the forty millisecond of the noise cleaning plus the hundred millisecond smoothing at the output .__c4
____uhhuh .__c1
____uhhuh .__c1
____um ==__c4
____so yeah .__c4
__z__so the - the - di- - the biggest ==__c4
____the problem f- - for me was to find a consistent threshold that works well across the different databases .__c4
____because i t- - i try to make it work on tr- - speechdat-car .__c4
____uhhuh .__c1
__z__and it fails on t. i. digits .__c4
